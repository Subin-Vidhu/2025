{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in /home/codespace/.python/current/lib/python3.12/site-packages (2.9.10)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.2.0)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (2.5.1+cpu)\n",
      "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (1.14.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /home/codespace/.local/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (434 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.27.0 regex-2024.11.6 safetensors-0.4.5 sentence-transformers-3.3.1 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.47.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2 numpy sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values, Json\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PostgresVectorStore:\n",
    "    def __init__(self, connection_string: str, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store with a PostgreSQL connection string.\n",
    "        \n",
    "        Args:\n",
    "            connection_string: PostgreSQL connection string\n",
    "            model_name: Name of the sentence-transformers model to use\n",
    "        \"\"\"\n",
    "        self.conn_string = connection_string\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def add_texts(self, texts: List[str], metadatas: List[dict] = None):\n",
    "        \"\"\"\n",
    "        Add texts to the vector store.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed and store\n",
    "            metadatas: Optional list of metadata dictionaries\n",
    "        \"\"\"\n",
    "        if metadatas is None:\n",
    "            metadatas = [{} for _ in texts]\n",
    "            \n",
    "        # Generate embeddings for all texts\n",
    "        embeddings = self.model.encode(texts)\n",
    "        \n",
    "        # Create document tuples\n",
    "        documents = [\n",
    "            (text, embedding.tolist(), metadata) \n",
    "            for text, embedding, metadata in zip(texts, embeddings, metadatas)\n",
    "        ]\n",
    "        \n",
    "        with psycopg2.connect(self.conn_string) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                values = [(doc[0], doc[1], Json(doc[2])) for doc in documents]\n",
    "                execute_values(cur, \"\"\"\n",
    "                    INSERT INTO document_embeddings (content, embedding, metadata)\n",
    "                    VALUES %s\n",
    "                \"\"\", values)\n",
    "    \n",
    "    def similarity_search(\n",
    "        self, \n",
    "        query: str, \n",
    "        limit: int = 5\n",
    "    ) -> List[Tuple[str, float, dict]]:\n",
    "        \"\"\"\n",
    "        Perform similarity search using cosine similarity.\n",
    "        \n",
    "        Args:\n",
    "            query: Text query to search for\n",
    "            limit: Maximum number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples containing (content, similarity_score, metadata)\n",
    "        \"\"\"\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = self.model.encode(query).tolist()\n",
    "        \n",
    "        with psycopg2.connect(self.conn_string) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(\"\"\"\n",
    "                    SELECT \n",
    "                        content,\n",
    "                        1 - (embedding <=> %s::vector) as similarity,\n",
    "                        metadata\n",
    "                    FROM document_embeddings\n",
    "                    ORDER BY embedding <=> %s::vector\n",
    "                    LIMIT %s\n",
    "                \"\"\", (query_embedding, query_embedding, limit))\n",
    "                \n",
    "                return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: Machine learning is a subset of artificial intelligence\n",
      "Similarity: 0.7109\n",
      "Metadata: {'source': 'sample2', 'category': 'technology'}\n",
      "---\n",
      "Content: Natural language processing helps computers understand human language\n",
      "Similarity: 0.3885\n",
      "Metadata: {'source': 'sample4', 'category': 'nlp'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize vector store with Docker PostgreSQL connection\n",
    "    store = PostgresVectorStore(\n",
    "        \"postgresql://vectordb:vectorpass@localhost:5432/vectordb\"\n",
    "    )\n",
    "    \n",
    "    # Example texts and metadata\n",
    "    texts = [\n",
    "        \"The quick brown fox jumps over the lazy dog\",\n",
    "        \"Machine learning is a subset of artificial intelligence\",\n",
    "        \"Python is a versatile programming language\",\n",
    "        \"Natural language processing helps computers understand human language\",\n",
    "        \"Vector databases are optimized for similarity search\"\n",
    "    ]\n",
    "    \n",
    "    metadatas = [\n",
    "        {\"source\": \"sample1\", \"category\": \"pangram\"},\n",
    "        {\"source\": \"sample2\", \"category\": \"technology\"},\n",
    "        {\"source\": \"sample3\", \"category\": \"programming\"},\n",
    "        {\"source\": \"sample4\", \"category\": \"nlp\"},\n",
    "        {\"source\": \"sample5\", \"category\": \"databases\"}\n",
    "    ]\n",
    "    \n",
    "    # Add documents\n",
    "    store.add_texts(texts, metadatas)\n",
    "    \n",
    "    # Perform similarity search\n",
    "    query = \"Tell me about AI and machine learning\"\n",
    "    results = store.similarity_search(query, limit=2)\n",
    "    \n",
    "    # Print results\n",
    "    for content, similarity, metadata in results:\n",
    "        print(f\"Content: {content}\")\n",
    "        print(f\"Similarity: {similarity:.4f}\")\n",
    "        print(f\"Metadata: {metadata}\")\n",
    "        print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
